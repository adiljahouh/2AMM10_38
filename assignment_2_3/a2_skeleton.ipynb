{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730fd591",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_2_3/a2_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f8d18",
   "metadata": {},
   "source": [
    "# Group Number: 38\n",
    "\n",
    "# Student 1:\n",
    "\n",
    "# Student 2:\n",
    "\n",
    "# Student 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec2056",
   "metadata": {},
   "source": [
    "# Downloading Data and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0580a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "import io\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0756591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zip(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    zipf = ZipFile(io.BytesIO(response.content))\n",
    "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
    "\n",
    "def load_array(zipfile, fn):\n",
    "    return np.load(io.BytesIO(zipfile[fn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell loads the training, validation or test data as numpy arrays,\n",
    "with the positions, initial velocities and charge data of the particles.\n",
    "\n",
    "The position arrays are shaped as\n",
    "[simulation id, time point (corresponding to t = 0, 0.5, 1 or 1.5), x/y spatial dimension, particle id].\n",
    "\n",
    "The initial velocity arrays are shaped as\n",
    "[simulation id, 1 (corresponding to t=0), x/y spatial dimension, particle id].\n",
    "\n",
    "The charge arrays are shaped as [simulation id, particle id, 1]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/OIgda2ZRG8v0eqB/download')\n",
    "\n",
    "features = ['positions', 'velocities', 'charges']\n",
    "    \n",
    "positions_train, velocities_train, charges_train = (load_array(data, f'data/train/{f}.npy') for f in features)\n",
    "positions_valid, velocities_valid, charges_valid = (load_array(data, f'data/valid/{f}.npy') for f in features)\n",
    "positions_test, velocities_test, charges_test = (load_array(data, f'data/test/{f}.npy') for f in features)\n",
    "\n",
    "print('Shapes of the training data:\\n')\n",
    "print(f'positions: {positions_train.shape}')\n",
    "print(f'velocities: {velocities_train.shape}')\n",
    "print(f'charges: {charges_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3ea4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('An example of retrieving data from the arrays:\\n\\n')\n",
    "\n",
    "sim_idx = 42\n",
    "t_idx = 2  # t_idx 0, 1, 2, 3 corresponds to t=0, 0.5, 1 and 1.5 respectively\n",
    "spatial_idx = (0,1)  # corresponds to both x and y dimension\n",
    "particle_idx = 3  # corresponds to particle with index 3\n",
    "\n",
    "p = positions_train[sim_idx, t_idx, spatial_idx, particle_idx]\n",
    "v = velocities_train[sim_idx, 0, spatial_idx, particle_idx]  # note: this array contains only the inital velocity -> hence the 0\n",
    "c = charges_train[sim_idx, particle_idx, 0] \n",
    "\n",
    "print(\n",
    "    f'In simulation {sim_idx} of the training set, particle {particle_idx} with charge {c} had coordinates {p}.\\nThe initial velocity of this particle was {v}.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec4c801",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a3438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Overview of no. datapoints:\\n')\n",
    "\n",
    "print(f'{len(positions_train)} train, {len(positions_valid)} validation, {len(positions_test)} test simulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9106543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example(pos, vel):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-5., 5.])\n",
    "    axes.set_ylim([-5., 5.])\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'brown']\n",
    "    for i in range(pos.shape[-1]):\n",
    "        plt.plot(pos[0, 0, i], pos[0, 1, i], 'd', color=colors[i])\n",
    "        plt.plot(pos[-1, 0, i], pos[-1, 1, i], 'x', color=colors[i])\n",
    "        plt.plot([pos[0, 0, i], pos[0, 0, i] + vel[0, 0, i]], [pos[0, 1, i], pos[0, 1, i] + vel[0, 1, i]], '--', color=colors[i])\n",
    "    fig.set_size_inches(7, 7)\n",
    "    plt.xlim(np.min(pos)-1, np.max(pos) +1)\n",
    "    plt.ylim(np.min(pos)-1, np.max(pos) +1)\n",
    "    plt.plot([], [], 'd', color='black', label='initial position')\n",
    "    plt.plot([], [], 'x', color='black', label='final position')\n",
    "    plt.plot([], [], '--', color='black', label='initial velocity \\ndirection and magnitude')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28681a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = np.random.randint(0, 10000)\n",
    "plot_example(positions_train[random_idx], velocities_train[random_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059b633c",
   "metadata": {},
   "source": [
    "# Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ecb529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, veloc, pos, charges,time_id=1):\n",
    "        self.velocity = torch.FloatTensor(veloc)\n",
    "        self.charges = torch.FloatTensor(charges)\n",
    "        self.position = torch.FloatTensor(pos)\n",
    "        self.time_id = time_id\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x_1 = self.velocity[index] #t=0 by default\n",
    "        x_2 = self.charges[index] #t=0 by default\n",
    "        x_2 = x_2.reshape(-1, 1, 5) # reshape from 128, 5, 1 -> 128, 1, 5\n",
    "        x_2 = x_2.repeat(1, 2, 1) # 128, 2, 5\n",
    "        x_3 = self.position[index, 0].view(1,2,5) # input pos of t=0\n",
    "        reshaped_array = torch.cat([x_1, x_2, x_3], dim=1)\n",
    "        y = self.position[index, self.time_id].view(1,2,5) # output pos of t=time_id\n",
    "        return reshaped_array, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.charges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8633eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=MyDataset(velocities_train, positions_train, charges_train, 1)\n",
    "val_dataset = MyDataset(velocities_valid, positions_valid, charges_valid, 1)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd42ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see shapes\n",
    "for x, y in train_loader:\n",
    "    # # print(x[0, :, :, :])\n",
    "    # print(y[0, :, :, :])\n",
    "    # print(y[:, :, :, :].view(128, 10)) # flattened\n",
    "    # print(\"Shape of tensor x: \", x.shape)\n",
    "    # print(\"Shape of tensor y: \", y.shape)\n",
    "    # break\n",
    "    print(\"veloc {sim, init_vel, x or y, ptxid} -  charge {sim, ptxid, charge} - pos {sim, time, x or y, ptxd}\")\n",
    "\n",
    "    print(x.shape)\n",
    "    break\n",
    "# normal nn  fix losses\n",
    "# fix dataloader done\n",
    "# data augmentation (flip the order of ptxid)\n",
    "# normalizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2874d",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde5ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple NN network for value prediction\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim,30)\n",
    "        self.layer2 = nn.Linear(30, 30)\n",
    "        self.layer3 = nn.Linear(30, 10)\n",
    "        # self.drop = nn.Dropout(0.2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        # x = self.drop(x)\n",
    "        x = F.relu(self.layer2(x))\n",
    "        # x = self.drop(x)\n",
    "        x = F.relu(self.layer3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea70d73",
   "metadata": {},
   "source": [
    "# Model Training REGULAR NEURAL NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af520ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN MODEL\n",
    "from tqdm import tqdm\n",
    "def train(model, train_loader, n_epochs, optimizer, criterion):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for _ in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "\n",
    "        for x, y in tqdm(train_loader):\n",
    "            try:\n",
    "                y = y.view(128, 10)\n",
    "                x = x.view(128, 30)\n",
    "            except RuntimeError:\n",
    "                y = y.view(16, 10)\n",
    "                x = x.view(16, 30)\n",
    "            batch_loss = 0.0\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            # print(outputs.shape)\n",
    "            # print(y.shape)\n",
    "            loss = criterion(outputs, y)\n",
    "            batch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(batch_loss)\n",
    "    # pt_loss = pt_loss/10\n",
    "    # running_loss += pt_loss\n",
    "            \n",
    "        # avg_train_loss = running_loss / (len(train_loader) * 128) # batch size\n",
    "        # train_losses.append(avg_train_loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for x, y in val_loader:\n",
    "                try:\n",
    "                    y = y.view(128, 10)\n",
    "                    x = x.view(128, 30)\n",
    "                except RuntimeError:\n",
    "                    y = y.view(80, 10)\n",
    "                    x = x.view(80, 30)\n",
    "                val_batch_loss = 0.0\n",
    "                outputs = model(x)\n",
    "                loss = criterion(outputs, y)\n",
    "                val_batch_loss += loss.item()\n",
    "                val_losses.append(val_batch_loss)\n",
    "        # avg_val_loss = val_running_loss / (len(val_loader) * 128) # batch size\n",
    "        # val_losses.append(avg_val_loss)\\\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95af5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-6\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction=\"mean\") # can do MSE/MAE depends on outliers\n",
    "model = SimpleModel(input_dim=30)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "trainloss, valloss = train(model= model, train_loader= train_loader, n_epochs=5, optimizer= optimizer, criterion=loss_fn)\n",
    "print(trainloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c9a548",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(valloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068baf21",
   "metadata": {},
   "source": [
    "## RNN TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c956ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTmodel RNN\n",
    "# NOT FINISHED\n",
    "#####\n",
    "#https://towardsdatascience.com/building-rnn-lstm-and-gru-for-time-series-using-pytorch-a46e5b094e7b\n",
    "####\n",
    "class LSTMModel(nn.Module):\n",
    "    # input dim are the features which should be only 1 right t=0?\n",
    "    # or is it 5 because 5 particles?\n",
    "    def __init__(self, input_dim =5 , hidden_dim = 256, layer_dim = 2, output_dim = 2, dropout_prob = 0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        # Defining the number of layers and the nodes in each layer\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
    "        )\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initializing hidden state for first input with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Initializing cell state for first input with zeros\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        # Forward propagation by passing in the input, hidden state, and cell state into the model\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
    "        # so that it can fit into the fully connected layer\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb3b29",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN MODEL\n",
    "from tqdm import tqdm\n",
    "def train(model, train_loader, n_epochs, optimizer, criterion):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "\n",
    "        for veloc, charges, position, y in tqdm(train_loader):\n",
    "            pt_loss = 0.0\n",
    "            init_veloc_xy = veloc[:, 0, :, :]\n",
    "            init_pos_xy = position[:, 0, :, :] \n",
    "            charge = charges[:, :, 0]\n",
    "            print(init_pos_xy.shape)\n",
    "            print(charge.shape)\n",
    "            print(init_veloc_xy.shape)\n",
    "            break\n",
    "            x = torch.cat([init_pos_xy, charge, init_veloc_xy], dim=0) \n",
    "            y = y[:, -1, :, -1] # get [128, 2] batch x,y coordinate\n",
    "            y = torch.squeeze(y) # flattens dimensions of 1\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            pt_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pt_loss = pt_loss/10\n",
    "            running_loss += pt_loss\n",
    "                    \n",
    "        avg_train_loss = running_loss / (len(train_loader) * 128) # batch size\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8240f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = nn.MSELoss(reduction=\"mean\") # can do MSE/MAE depends on outliers\n",
    "RNN_network = LSTMModel()\n",
    "optimizer = optim.Adam(RNN_network.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "train_loss = train(model= RNN_network, train_loader=train_loader, n_epochs=10, optimizer= optimizer, criterion=loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c4099",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4158c455f6fbd238463d225e32374cd628fb465de0e99af1b601eff60f49c402"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
