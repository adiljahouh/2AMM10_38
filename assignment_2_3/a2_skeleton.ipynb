{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730fd591",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_2_3/a2_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f8d18",
   "metadata": {},
   "source": [
    "# Group Number: 38\n",
    "\n",
    "# Student 1:\n",
    "\n",
    "# Student 2:\n",
    "\n",
    "# Student 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec2056",
   "metadata": {},
   "source": [
    "# Downloading Data and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0580a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adil\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.8' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "import io\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0756591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zip(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    zipf = ZipFile(io.BytesIO(response.content))\n",
    "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
    "\n",
    "def load_array(zipfile, fn):\n",
    "    return np.load(io.BytesIO(zipfile[fn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb77a4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the training data:\n",
      "\n",
      "positions: (10000, 4, 2, 5)\n",
      "velocities: (10000, 1, 2, 5)\n",
      "charges: (10000, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell loads the training, validation or test data as numpy arrays,\n",
    "with the positions, initial velocities and charge data of the particles.\n",
    "\n",
    "The position arrays are shaped as\n",
    "[simulation id, time point (corresponding to t = 0, 0.5, 1 or 1.5), x/y spatial dimension, particle id].\n",
    "\n",
    "The initial velocity arrays are shaped as\n",
    "[simulation id, 1 (corresponding to t=0), x/y spatial dimension, particle id].\n",
    "\n",
    "The charge arrays are shaped as [simulation id, particle id, 1]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/OIgda2ZRG8v0eqB/download')\n",
    "\n",
    "features = ['positions', 'velocities', 'charges']\n",
    "    \n",
    "positions_train, velocities_train, charges_train = (load_array(data, f'data/train/{f}.npy') for f in features)\n",
    "positions_valid, velocities_valid, charges_valid = (load_array(data, f'data/valid/{f}.npy') for f in features)\n",
    "positions_test, velocities_test, charges_test = (load_array(data, f'data/test/{f}.npy') for f in features)\n",
    "\n",
    "print('Shapes of the training data:\\n')\n",
    "print(f'positions: {positions_train.shape}')\n",
    "print(f'velocities: {velocities_train.shape}')\n",
    "print(f'charges: {charges_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c3ea4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of retrieving data from the arrays:\n",
      "\n",
      "\n",
      "In simulation 42 of the training set, particle 3 with charge -1.0 had coordinates [ 2.05159559 -1.46130851].\n",
      "The initial velocity of this particle was [ 0.28402364 -0.24784824].\n"
     ]
    }
   ],
   "source": [
    "print('An example of retrieving data from the arrays:\\n\\n')\n",
    "\n",
    "sim_idx = 42\n",
    "t_idx = 2  # t_idx 0, 1, 2, 3 corresponds to t=0, 0.5, 1 and 1.5 respectively\n",
    "spatial_idx = (0,1)  # corresponds to both x and y dimension\n",
    "particle_idx = 3  # corresponds to particle with index 3\n",
    "\n",
    "p = positions_train[sim_idx, t_idx, spatial_idx, particle_idx]\n",
    "v = velocities_train[sim_idx, 0, spatial_idx, particle_idx]  # note: this array contains only the inital velocity -> hence the 0\n",
    "c = charges_train[sim_idx, particle_idx, 0] \n",
    "\n",
    "print(\n",
    "    f'In simulation {sim_idx} of the training set, particle {particle_idx} with charge {c} had coordinates {p}.\\nThe initial velocity of this particle was {v}.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ec4c801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n"
     ]
    }
   ],
   "source": [
    "print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10a3438a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of no. datapoints:\n",
      "\n",
      "10000 train, 2000 validation, 2000 test simulations\n"
     ]
    }
   ],
   "source": [
    "print('Overview of no. datapoints:\\n')\n",
    "\n",
    "print(f'{len(positions_train)} train, {len(positions_valid)} validation, {len(positions_test)} test simulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9106543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example(pos, vel):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-5., 5.])\n",
    "    axes.set_ylim([-5., 5.])\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'brown']\n",
    "    for i in range(pos.shape[-1]):\n",
    "        plt.plot(pos[0, 0, i], pos[0, 1, i], 'd', color=colors[i])\n",
    "        plt.plot(pos[-1, 0, i], pos[-1, 1, i], 'x', color=colors[i])\n",
    "        plt.plot([pos[0, 0, i], pos[0, 0, i] + vel[0, 0, i]], [pos[0, 1, i], pos[0, 1, i] + vel[0, 1, i]], '--', color=colors[i])\n",
    "    fig.set_size_inches(7, 7)\n",
    "    plt.xlim(np.min(pos)-1, np.max(pos) +1)\n",
    "    plt.ylim(np.min(pos)-1, np.max(pos) +1)\n",
    "    plt.plot([], [], 'd', color='black', label='initial position')\n",
    "    plt.plot([], [], 'x', color='black', label='final position')\n",
    "    plt.plot([], [], '--', color='black', label='initial velocity \\ndirection and magnitude')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d28681a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_idx = np.random.randint(0, 10000)\n",
    "plot_example(positions_train[random_idx], velocities_train[random_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059b633c",
   "metadata": {},
   "source": [
    "# Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddd17cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\"\"\"\n",
    "Get all lists of indices to shuffle the train set\n",
    "\"\"\"\n",
    "def shuffle_indices(indices):\n",
    "\n",
    "    comb_list = []\n",
    "    for x in itertools.permutations(indices):\n",
    "        comb_list.append(list(x))\n",
    "    return comb_list\n",
    "\n",
    "list_indices = shuffle_indices(indices = [0, 1, 2, 3, 4])\n",
    "print(len(list_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c0ee28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Shuffle the train set such that we move\n",
    "each particle to a different location\n",
    "such that the model is permutation invariant\n",
    "\"\"\"\n",
    "# too difficult to implement \n",
    "\n",
    "for sim in range(positions_train.shape[0]):\n",
    "    for i in list_indices[:10]:\n",
    "        # print(positions_train[sim])\n",
    "        # print(\"\\n\")\n",
    "        # print(np.transpose(positions_train[sim, :, :, i]))\n",
    "        break\n",
    "    break   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6ecb529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "from torch.nn.functional import normalize\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, veloc, pos, charges,time_id, norm, transform=None):\n",
    "        self.velocity = torch.FloatTensor(veloc)\n",
    "        self.charges = torch.FloatTensor(charges)\n",
    "        self.position = torch.FloatTensor(pos)\n",
    "        self.time_id = time_id\n",
    "        self.norm = norm\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x_1 = self.velocity[index] #t=0 by default\n",
    "        x_2 = self.charges[index] #t=0 by default\n",
    "        x_2 = x_2.reshape(-1, 1, 5) # reshape from 128, 5, 1 -> 128, 1, 5\n",
    "        x_2 = x_2.repeat(1, 2, 1) # 128, 2, 5\n",
    "        x_3 = self.position[index, 0].view(1,2,5) # input pos of t=0\n",
    "        reshaped_array = torch.cat([x_1, x_2, x_3], dim=1)\n",
    "        y = self.position[index, self.time_id].view(1,2,5) # output pos of t=time_id\n",
    "\n",
    "        if self.norm is not False:\n",
    "            reshaped_array = normalize(reshaped_array)\n",
    "            y = normalize(y)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            reshaped_array = self.transform(reshaped_array)\n",
    "            y = self.transform(y)\n",
    "\n",
    "        return reshaped_array, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.charges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2874d",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dde5ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple NN network for value prediction\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 32)\n",
    "        self.layer2 = nn.Linear(32, 64)\n",
    "        self.layer3 = nn.Linear(64, 64)\n",
    "        self.layer4 = nn.Linear(64, 10)\n",
    "        # self.layer5 = nn.Linear(32, 10)\n",
    "        self.norm1 = nn.BatchNorm1d(32)\n",
    "        self.norm2 = nn.BatchNorm1d(64)\n",
    "        self.norm3 = nn.BatchNorm1d(10)\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.norm1(F.relu(self.layer1(x)))\n",
    "        x = self.drop(x)\n",
    "        x = self.norm2(F.relu(self.layer2(x)))\n",
    "        x = self.drop(x)\n",
    "        x = self.norm2(F.relu(self.layer3(x)))\n",
    "        x = self.drop(x)\n",
    "        x = self.norm3(F.relu(self.layer4(x)))\n",
    "        # x = F.relu(self.layer4(x))\n",
    "        # x = F.relu(self.layer5(x))\n",
    "        # x = self.drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea70d73",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e9754c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving and loading checkpoint mechanisms \n",
    "# modules adapted from https://github.com/ttchengab/One_Shot_Pytorch/blob/master/network.ipynb\n",
    "\n",
    "def save_checkpoint(save_path, model, optimizer, val_loss):\n",
    "  \"\"\"\n",
    "  Utility function for saving the model \n",
    "\n",
    "  Input\n",
    "    --save_path: path to save the model\n",
    "    --model: model to be saved\n",
    "    --optimizer: optimizer to be saved\n",
    "    --val_loss: lowest validation loss so far\n",
    "\n",
    "  Output\n",
    "    Saved model as pt file\n",
    "  \"\"\"\n",
    "  if save_path==None:\n",
    "      return\n",
    "  save_path = save_path \n",
    "  state_dict = {'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss}\n",
    "\n",
    "  torch.save(state_dict, save_path)\n",
    "  print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_checkpoint(model, optimizer):\n",
    "  \"\"\"\n",
    "  Utility function to load a saved model\n",
    "  Input\n",
    "    --model: model object to load the weights into\n",
    "    --optimizer: optimizer object\n",
    "    \n",
    "  Output:\n",
    "    Validation loss\n",
    "  \"\"\"\n",
    "  save_path = f'SiameseNetwork.pt'\n",
    "  state_dict = torch.load(save_path)\n",
    "  model.load_state_dict(state_dict['model_state_dict'])\n",
    "  optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "  val_loss = state_dict['val_loss']\n",
    "  print(f'Model loaded from <== {save_path}')\n",
    "  \n",
    "  return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3af520ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN MODEL\n",
    "from tqdm import tqdm\n",
    "def train(model, train_loader, val_loader, n_epochs, optimizer, criterion, save_name):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float(\"Inf\")\n",
    "    for _ in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "\n",
    "        for x, y in tqdm(train_loader):\n",
    "            y = y.view(y.shape[0], 10)\n",
    "            x = x.view(x.shape[0], 30)\n",
    "            batch_loss = 0.0\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            batch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        avg_train_loss = batch_loss / len(train_loader) # batch size\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for x, y in val_loader:\n",
    "                y = y.view(y.shape[0], 10)\n",
    "                x = x.view(x.shape[0], 30)\n",
    "                val_batch_loss = 0.0\n",
    "                outputs = model(x)\n",
    "                # output_val.append(outputs)\n",
    "                loss = criterion(outputs, y)\n",
    "                val_batch_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_batch_loss / len(val_loader) # batch size\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            save_checkpoint(save_name, model, optimizer, best_val_loss)\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4b95aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-6\n",
    "\n",
    "model_10000_1 = SimpleModel(input_dim=30)\n",
    "model_10000_2 = SimpleModel(input_dim=30)\n",
    "model_10000_3 = SimpleModel(input_dim=30)\n",
    "model_1000_1 = SimpleModel(input_dim=30)\n",
    "model_1000_2 = SimpleModel(input_dim=30)\n",
    "model_1000_3 = SimpleModel(input_dim=30)\n",
    "model_100_1 = SimpleModel(input_dim=30)\n",
    "model_100_2 = SimpleModel(input_dim=30)\n",
    "model_100_3 = SimpleModel(input_dim=30)\n",
    "\n",
    "optimizer_10000_1 = optim.Adam(model_10000_1.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "optimizer_10000_2 = optim.Adam(model_10000_2.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "optimizer_10000_3 = optim.Adam(model_10000_3.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "optimizer_1000_1  = optim.Adam(model_1000_1.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "optimizer_1000_2  = optim.Adam(model_1000_2.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "optimizer_1000_3  = optim.Adam(model_1000_3.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "optimizer_100_1  =  optim.Adam(model_100_1.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "optimizer_100_2 =   optim.Adam(model_100_2.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "optimizer_100_3 =   optim.Adam(model_100_3.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95af5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(samples, timeids, models, optimizers, criterion):\n",
    "    count = 0\n",
    "    for sample in samples:\n",
    "        for timeid in timeids:\n",
    "            train_dataset =MyDataset(velocities_train[:sample], positions_train[:sample], charges_train[:sample], time_id = timeid, norm = True, transform=None) \n",
    "            val_dataset = MyDataset(velocities_valid, positions_valid, charges_valid, time_id = timeid, norm = True, transform=None) \n",
    "\n",
    "            train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128) \n",
    "            val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=128) \n",
    "            trainloss, valloss = train(model= models[count], train_loader= train_loader, val_loader=val_loader, n_epochs=10, optimizer= optimizers[count], criterion=criterion, save_name='models\\\\NN' + '_' + str(sample) + '_' + str(timeid) + '.pt')\n",
    "            plt.figure()\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('loss')\n",
    "            plt.plot(trainloss, label='Train Loss')\n",
    "            plt.plot(valloss, label=\"Validation Loss\")\n",
    "            plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "            plt.savefig(\"images\\\\NN\" + '_' + str(sample) + '_' + str(timeid) + \".png\")\n",
    "            plt.show\n",
    "            plt.close()\n",
    "            print(count)\n",
    "            count +=1\n",
    "            \n",
    "\n",
    "samples = [100, 1000, 10000]\n",
    "timeids = [1, 2, 3]\n",
    "models = [model_100_1, model_100_2, model_100_3, model_1000_1, model_1000_2, model_1000_3, model_10000_1, model_10000_2, model_10000_3]\n",
    "optimizers = [optimizer_100_1, optimizer_100_2, optimizer_100_3, optimizer_1000_1, optimizer_1000_2, optimizer_1000_3, optimizer_10000_1, optimizer_10000_2, optimizer_10000_3]\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-6\n",
    "loss_fn = nn.MSELoss(reduction=\"mean\") # can do MSE/MAE depends on outliers\n",
    "train_loop(samples, timeids, models, optimizers, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7033d3e",
   "metadata": {},
   "source": [
    "## Prediction + label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "12205fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET OUR PREDICTIONS AND LABELS\n",
    "from varname import nameof\n",
    "\n",
    "from tqdm import tqdm\n",
    "def test(models, testloaders):\n",
    "    output_dict = dict()\n",
    "    with torch.no_grad():\n",
    "        models_1 = models[::3] # models for time horizon 0.5 (timeid = 1)\n",
    "        models_2 = models[1::3] # models for time horizon 1 (timeid = 2)\n",
    "        models_3 = models[2::3] # models for time horizon 1.5 (timeid = 3)\n",
    "        for index, model in enumerate(models_1):\n",
    "            output_test = [] \n",
    "            labels = []\n",
    "            model.eval()\n",
    "            count = 0\n",
    "            for x, y in testloaders[0]:\n",
    "                y = y.view(y.shape[0], 10)\n",
    "                x = x.view(x.shape[0], 30)\n",
    "                outputs = model(x)\n",
    "                output_test.append(outputs)\n",
    "                labels.append(y)\n",
    "                count += 1\n",
    "            output_dict['model_100_' + str(index+1) + '_output'] = output_test\n",
    "            output_dict['model_100_' + str(index+1) + '_labels'] = labels\n",
    "        for index, model in enumerate(models_2):\n",
    "            model.eval()\n",
    "            for x, y in testloaders[1]:\n",
    "                y = y.view(y.shape[0], 10)\n",
    "                x = x.view(x.shape[0], 30)\n",
    "                outputs = model(x)\n",
    "                output_test.append(outputs)\n",
    "                labels.append(y)\n",
    "            output_dict['model_1000_' + str(index+1) + '_output'] = output_test\n",
    "            output_dict['model_1000_' + str(index+1) + '_labels'] = labels\n",
    "        for index, model in enumerate(models_3):\n",
    "            model.eval()\n",
    "            for x, y in testloaders[2]:\n",
    "                y = y.view(y.shape[0], 10)\n",
    "                x = x.view(x.shape[0], 30)\n",
    "                outputs = model(x)\n",
    "                output_test.append(outputs)\n",
    "                labels.append(y)\n",
    "            output_dict['model_10000_' + str(index+1) + '_output'] = output_test\n",
    "            output_dict['model_10000_' + str(index+1) + '_labels'] = labels\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2e5db1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model_100_1_output', 'model_100_1_labels', 'model_100_2_output', 'model_100_2_labels', 'model_100_3_output', 'model_100_3_labels', 'model_1000_1_output', 'model_1000_1_labels', 'model_1000_2_output', 'model_1000_2_labels', 'model_1000_3_output', 'model_1000_3_labels', 'model_10000_1_output', 'model_10000_1_labels', 'model_10000_2_output', 'model_10000_2_labels', 'model_10000_3_output', 'model_10000_3_labels'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_1 = MyDataset(velocities_test, positions_test, charges_test, time_id = 1, norm = True, transform=None)\n",
    "test_dataset_2 = MyDataset(velocities_test, positions_test, charges_test, time_id = 2, norm = True, transform=None)\n",
    "test_dataset_3 = MyDataset(velocities_test, positions_test, charges_test, time_id = 3, norm = True, transform=None)\n",
    "test_loader_1 = torch.utils.data.DataLoader(test_dataset_1, batch_size=128) # len(test_dataset) = 2000\n",
    "test_loader_2 = torch.utils.data.DataLoader(test_dataset_2, batch_size=128) # len(test_dataset) = 2000\n",
    "test_loader_3 = torch.utils.data.DataLoader(test_dataset_3, batch_size=128) # len(test_dataset) = 2000\n",
    "\n",
    "testloaders = [test_loader_1, test_loader_2, test_loader_3]\n",
    "test_dict = test(models, testloaders)\n",
    "test_dict.keys()\n",
    "\n",
    "# Right now we return the prediction and the labels for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d2a03769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append predictions and labels to list\n",
    "def split_output(test_output, labels):\n",
    "    test_x = []\n",
    "    test_y = []\n",
    "    act_x = []\n",
    "    act_y = []\n",
    "    for batch in test_output:\n",
    "        arr = batch.numpy()\n",
    "        for sim in range(arr.shape[0]):\n",
    "            y = arr[sim][1::2] # take every even index\n",
    "            x = arr[sim][::2] # take every even index\n",
    "        \n",
    "            test_x.extend(x)\n",
    "            test_y.extend(y)\n",
    "    \n",
    "    for lab_batch in labels:\n",
    "        arr_lab = lab_batch.numpy()\n",
    "        for sim in range(arr_lab.shape[0]):\n",
    "            y_lab = arr_lab[sim][1::2] # take every even index\n",
    "            x_lab = arr_lab[sim][::2] # take every even index\n",
    "        \n",
    "            act_x.extend(x_lab)\n",
    "            act_y.extend(y_lab)\n",
    "    \n",
    "    return test_x, test_y, act_x, act_y\n",
    "\n",
    "x_pred, y_pred, x_act, y_act = split_output(test_dict['model_100_1_output'], test_dict['model_100_1_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f11070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# plt.xlabel('simulations')\n",
    "# plt.ylabel('position at t=0.5')\n",
    "# fig.set_size_inches(10, 7)\n",
    "# plt.plot(x_pred[::50], label='NN x prediction') \n",
    "# plt.plot(y_pred[::50], label='NN y predication') \n",
    "# plt.plot(baseline_pred_x[::50], label='Formula x prediction') # not normalized\n",
    "# plt.plot(baseline_pred_y[::50], label='Formula y prediction') # not normalized\n",
    "# plt.plot(x_act[::50], label='x actual ')\n",
    "# plt.plot(y_act[::50], label='y actual')\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "# plt.show()\n",
    "\n",
    "# PROBLEM: DATA IS NORMALIZED BUT BASELINE PREDICTIONS ARENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc07c9",
   "metadata": {},
   "source": [
    "## Baseline predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b60737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formala prediction for each t\n",
    "def baseline_prediction(t):\n",
    "    baseline_pred_x = []\n",
    "    baseline_pred_y = []\n",
    "    for sim in range(2000): # should be 2000\n",
    "        for ptxd in range(5):\n",
    "            #x_t = x_0 + v_0 * t for (x, y)\n",
    "            x_pos, y_pos = (positions_test[sim, 0, 0, ptxd]) + (velocities_test[sim, 0, 0, ptxd]*t), positions_test[sim, 0, 1, ptxd] + (velocities_test[sim, 0, 1, ptxd]*t)\n",
    "            baseline_pred_x.append(x_pos)\n",
    "            baseline_pred_y.append(y_pos)\n",
    "    return baseline_pred_x, baseline_pred_y\n",
    "# charges_test\n",
    "baseline_pred_x, baseline_pred_y = baseline_prediction(t=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb3b29",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4604e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract outputs from labels and avg loss\n",
    "# subtract baseline from labels and avg loss\n",
    "# compare both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068baf21",
   "metadata": {},
   "source": [
    "## RNN TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c956ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTmodel RNN\n",
    "#####\n",
    "#https://towardsdatascience.com/building-rnn-lstm-and-gru-for-time-series-using-pytorch-a46e5b094e7b\n",
    "####\n",
    "class LSTMModel(nn.Module):\n",
    "    # input dim are the features which should be only 1 right t=0?\n",
    "    # or is it 5 because 5 particles?\n",
    "    def __init__(self, input_dim = 30 , hidden_dim = 256, layer_dim = 2, output_dim = 10, dropout_prob = 0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        # Defining the number of layers and the nodes in each layer\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "\n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
    "        )\n",
    "\n",
    "        # Fully connected layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initializing hidden state for first input with zeros\n",
    "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # Initializing cell state for first input with zeros\n",
    "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
    "\n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        # Forward propagation by passing in the input, hidden state, and cell state into the model\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "\n",
    "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
    "        # so that it can fit into the fully connected layer\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a33d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN MODEL\n",
    "from tqdm import tqdm\n",
    "def trainRNN(model, train_loader, n_epochs, optimizer, criterion):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    for _ in range(1, n_epochs + 1):\n",
    "        output_val = [] #get output of last epoch in val\n",
    "        model.train()\n",
    "\n",
    "        for x, y in tqdm(train_loader):\n",
    "            y = y.view(y.shape[0], 10)\n",
    "            x = x.view(x.shape[0], 1, 30)\n",
    "            batch_loss = 0.0\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            outputs = outputs.squeeze()\n",
    "            loss = criterion(outputs, y)\n",
    "            batch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        avg_train_loss = batch_loss / len(train_loader) # batch size\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for x, y in val_loader:\n",
    "                y = y.view(y.shape[0], 10)\n",
    "                x = x.view(x.shape[0], 1, 30)  \n",
    "                val_batch_loss = 0.0\n",
    "                outputs = model(x)\n",
    "                output_val.append(outputs)\n",
    "                loss = criterion(outputs, y)\n",
    "                val_batch_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_batch_loss / len(val_loader) # batch size\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "    return train_losses, val_losses, output_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8240f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_fn = nn.MSELoss(reduction=\"mean\") # can do MSE/MAE depends on outliers\n",
    "RNN_network = LSTMModel()\n",
    "optimizer = optim.Adam(RNN_network.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "trainloss, valloss, output_val = trainRNN(model= RNN_network, train_loader=train_loader, n_epochs=10, optimizer= optimizer, criterion=loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9c4099",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(trainloss, label='Train Loss')\n",
    "plt.plot(valloss, label=\"Validation Loss\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4158c455f6fbd238463d225e32374cd628fb465de0e99af1b601eff60f49c402"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
