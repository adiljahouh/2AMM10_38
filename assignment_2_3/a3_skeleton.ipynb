{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "963690b2",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_2_3/a3_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8459f1",
   "metadata": {},
   "source": [
    "# Group Number:\n",
    "\n",
    "# Student 1: Adil \n",
    "\n",
    "# Student 2: Anvitha\n",
    "\n",
    "# Student 3: Srinidhi Ilango"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde28458",
   "metadata": {},
   "source": [
    "# Downloading Data and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0580a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ce00edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zip(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    zipf = ZipFile(io.BytesIO(response.content))\n",
    "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
    "\n",
    "def load_pickle(zipfile, fn):\n",
    "    return pickle.load(io.BytesIO(zipfile[fn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb77a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/cwqGaS22KXgnXtg/download')\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "simulation_{train, valid, test} is stored as a list of simulations. \n",
    "Each simulation is a numpy array of size (t, 2): For t timesteps an x and y coordinate of our particle.\n",
    "\"\"\"\n",
    "simulation_train = load_pickle(data, 'data/train/simulation.pickle')  # 3.1 + 3.2\n",
    "simulation_valid = load_pickle(data, 'data/valid/simulation.pickle')  # 3.1 + 3.2\n",
    "simulation_test = load_pickle(data, 'data/test/simulation.pickle')  # 3.1 + 3.2\n",
    "\n",
    "\"\"\"\n",
    "charges_{train, valid, test} is stored as a list of simulation-charges. \n",
    "These charges are stored as numpy arrays of size (3,): One value for each charge.\n",
    "\"\"\"\n",
    "charges_train = load_pickle(data, 'data/train/charges.pickle')  # 3.1\n",
    "charges_valid = load_pickle(data, 'data/valid/charges.pickle')  # 3.1\n",
    "charges_test = load_pickle(data, 'data/test/charges.pickle')  # 3.1\n",
    "\n",
    "\"\"\"\n",
    "simulation_continued_{train, valid, test} is stored as a list of simulations. \n",
    "Each simulation is a numpy array of size (t, 2): For t timesteps an x and y coordinate of our particle.\n",
    "\"\"\"\n",
    "simulation_continued_train = load_pickle(data, 'data/train/simulation_continued.pickle')  # 3.2\n",
    "simulation_continued_valid = load_pickle(data, 'data/valid/simulation_continued.pickle')  # 3.2\n",
    "simulation_continued_test = load_pickle(data, 'data/test/simulation_continued.pickle')  # 3.2\n",
    "\n",
    "\"\"\"\n",
    "Note that the indices are shared throughout the different lists, e.g., for the 4th training simulation:\n",
    "simulation_train[3] contains its initial simulation\n",
    "charges_train[3] contains the charges associated with the simulation\n",
    "simulation_continued_train[3] contains the continuation of the simulation \n",
    "                --> simulation_continued_train[3][0] is the state after simulation_train[3][-1]\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a3438a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of no. datapoints:\n",
      "\n",
      "Task 3.1:\n",
      "800 train, 100 validation, 100 test simulations\n",
      "800 train, 100 validation, 100 test charge pairs\n",
      "\n",
      "Task 3.2:\n",
      "Since len(simulation_continued_train) < len(simulation_train), we can only use a subset of initial simulations\n",
      "We cut simulation_train down to the first 150 samples in simulation_train_task32\n",
      "150 train, 100 validation, 100 test simulations\n",
      "150 train, 100 validation, 100 test continuations\n",
      "\n",
      "For task 3.1, use:\n",
      "simulation_train + charges_train\n",
      "simulation_valid + charges_valid\n",
      "simulation_test + charges_test\n",
      "\n",
      "For task 3.2, use:\n",
      "simulation_train_task32 + simulation_continued_train\n",
      "simulation_valid + simulation_continued_valid\n",
      "simulation_test + simulation_continued_test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Overview of no. datapoints:\\n')\n",
    "\n",
    "print('Task 3.1:')\n",
    "print(f'{len(simulation_train)} train, {len(simulation_valid)} validation, {len(simulation_test)} test simulations')\n",
    "print(f'{len(charges_train)} train, {len(charges_valid)} validation, {len(charges_test)} test charge pairs')\n",
    "print()\n",
    "\n",
    "print('Task 3.2:')\n",
    "print('Since len(simulation_continued_train) < len(simulation_train), we can only use a subset of initial simulations')\n",
    "print('We cut simulation_train down to the first 150 samples in simulation_train_task32')\n",
    "simulation_train_task32 = simulation_train[:150]\n",
    "print(f'{len(simulation_train_task32)} train, {len(simulation_valid)} validation, {len(simulation_test)} test simulations')\n",
    "print(f'{len(simulation_continued_train)} train, {len(simulation_continued_valid)} validation, {len(simulation_continued_test)} test continuations')\n",
    "\n",
    "print(f\"\"\"\n",
    "For task 3.1, use:\n",
    "{chr(10).join([\"simulation_{} + charges_{}\".format(t, t) for t in [\"train\", \"valid\", \"test\"]])}\n",
    "\n",
    "For task 3.2, use:\n",
    "{chr(10).join([\"simulation_{} + simulation_continued_{}\".format(*((t[0], t[1]) if isinstance(t, tuple) else (t, t))) for t in [(\"train_task32\", \"train\"), \"valid\", \"test\"]])}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cfafdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print some shapes:\n",
      "\n",
      "simulation_train[0].shape: (103, 2) -> (t, 2), (x, y) at every t)\n",
      "charges_train[0].shape: (3,) -> charges for the simulation\n",
      "simulation_continued_train[0].shape: (54, 2) -> (t, 2), (x, y) at every t)\n",
      "----\n",
      "\n",
      "simulation_train[1].shape: (97, 2) -> (t, 2), (x, y) at every t)\n",
      "charges_train[1].shape: (3,) -> charges for the simulation\n",
      "simulation_continued_train[1].shape: (45, 2) -> (t, 2), (x, y) at every t)\n",
      "----\n",
      "\n",
      "simulation_train[2].shape: (99, 2) -> (t, 2), (x, y) at every t)\n",
      "charges_train[2].shape: (3,) -> charges for the simulation\n",
      "simulation_continued_train[2].shape: (47, 2) -> (t, 2), (x, y) at every t)\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Print some shapes:\\n')\n",
    "for i in range(3):\n",
    "    print('simulation_train[{}].shape:'.format(i), simulation_train[i].shape, '-> (t, 2), (x, y) at every t)')\n",
    "    print('charges_train[{}].shape:'.format(i), charges_train[i].shape, '-> charges for the simulation')\n",
    "    print('simulation_continued_train[{}].shape:'.format(i), simulation_continued_train[i].shape, '-> (t, 2), (x, y) at every t)')\n",
    "    print('----\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9106543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example(x, x_gt=None, x_pred=None, fn=None):\n",
    "    charge_locations = np.array([[-1.53846154, -1.53846154],\n",
    "                                 [ 1.53846154, -1.53846154],\n",
    "                                 [ 0.        ,  1.53846154]])  # charge locations are fixed\n",
    "    fig = plt.figure()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-5., 5.])\n",
    "    axes.set_ylim([-5., 5.])\n",
    "    cmap = matplotlib.cm.get_cmap('tab20')\n",
    "    plt.plot(x[:, 0], x[:, 1], color=cmap(0))\n",
    "    plt.plot(x[0, 0], x[0, 1], 'd', color=cmap(1))\n",
    "    fig.set_size_inches(5, 5)\n",
    "    for charge in charge_locations:\n",
    "        plt.plot(charge[0], charge[1], 'd', color='black')\n",
    "    if x_gt is not None:\n",
    "        plt.plot(x_gt[:, 0], x_gt[:, 1], color='red', linewidth=.5)\n",
    "    if x_pred is not None:\n",
    "        plt.plot(x_pred[:, 0], x_pred[:, 1], color='green', linestyle='--')\n",
    "    if fn is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d28681a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charges are [-0.09808531 -0.5563076  -0.58221579]\n"
     ]
    }
   ],
   "source": [
    "test_idx = np.random.randint(150)\n",
    "plot_example(simulation_train[test_idx], simulation_continued_train[test_idx])\n",
    "print(f'Charges are {charges_train[test_idx]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "566bfb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving and loading checkpoint mechanisms \n",
    "# modules adapted from https://github.com/ttchengab/One_Shot_Pytorch/blob/master/network.ipynb\n",
    "\n",
    "def save_checkpoint(save_path, model, optimizer, val_loss):\n",
    "  \"\"\"\n",
    "  Utility function for saving the model \n",
    "\n",
    "  Input\n",
    "    --save_path: path to save the model\n",
    "    --model: model to be saved\n",
    "    --optimizer: optimizer to be saved\n",
    "    --val_loss: lowest validation loss so far\n",
    "\n",
    "  Output\n",
    "    Saved model as pt file\n",
    "  \"\"\"\n",
    "  if save_path==None:\n",
    "      return\n",
    "  save_path = save_path \n",
    "  state_dict = {'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss}\n",
    "\n",
    "  torch.save(state_dict, save_path)\n",
    "  print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_checkpoint(model, optimizer):\n",
    "  \"\"\"\n",
    "  Utility function to load a saved model\n",
    "  Input\n",
    "    --model: model object to load the weights into\n",
    "    --optimizer: optimizer object\n",
    "    \n",
    "  Output:\n",
    "    Validation loss\n",
    "  \"\"\"\n",
    "  save_path = f'SiameseNetwork.pt'\n",
    "  state_dict = torch.load(save_path)\n",
    "  model.load_state_dict(state_dict['model_state_dict'])\n",
    "  optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "  val_loss = state_dict['val_loss']\n",
    "  print(f'Model loaded from <== {save_path}')\n",
    "  \n",
    "  return val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883762b1",
   "metadata": {},
   "source": [
    "# Task 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1ddabe",
   "metadata": {},
   "source": [
    "## Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fe48be",
   "metadata": {},
   "source": [
    "Here, we deliberated over one of the following two options as the simulations have different lengths:\n",
    "1. zero padding to match the simulation lenghts\n",
    "2. without zero padding, pass one simuation at a time into the network and aggregate the outputs for backprop [ref1](https://discuss.pytorch.org/t/dataloader-for-various-length-of-data/6418/12#:~:text=2%20MONTHS%20LATER-,GalAvineri,-cdjhz), [ref2](https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch)\n",
    "\n",
    "We now try the second option <br>\n",
    "-- the model should be invariant to rotation, not sure about the implementation\n",
    "[REF](https://discuss.pytorch.org/t/dataloader-for-various-length-of-data/6418/13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd9df856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\installations\\anaconda3\\envs\\dl\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#todo \n",
    "#1: can add data normalization later\n",
    "#2: data augmentation - slice through longer time points as the outputs must remain same\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "\n",
    "def collate_batch(batch):\n",
    "    '''\n",
    "    Args:\n",
    "        batch: batch sizes list of tuples (features, target)\n",
    "    \n",
    "    Returns:\n",
    "        packed data and corresponding targets\n",
    "    \n",
    "    '''\n",
    "    data = [torch.from_numpy(item[0]).float() for item in batch]\n",
    "    lengths = [d.size(0) for d in data]\n",
    "\n",
    "    padded_data = pad_sequence(data, batch_first=True, padding_value=0)\n",
    "    packed_data = pack_padded_sequence(padded_data, lengths, batch_first=True, enforce_sorted=False)\n",
    "    \n",
    "    targets = np.array([item[1] for item in batch])\n",
    "\n",
    "    return packed_data, torch.tensor(targets).float() #.to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec1e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a DataLoaders for training, validation and testing\n",
    " \n",
    "batch_len = 8\n",
    "\n",
    "train_loader = DataLoader(tuple(zip(simulation_train, charges_train)), batch_size = batch_len, \n",
    "                        collate_fn = collate_batch,pin_memory=True)\n",
    "\n",
    "val_loader = DataLoader(tuple(zip(simulation_valid, charges_valid)), batch_size = batch_len, \n",
    "                        collate_fn = collate_batch,pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(tuple(zip(simulation_test, charges_train)),batch_size=1,\n",
    "                        collate_fn = collate_batch,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af0e89",
   "metadata": {},
   "source": [
    "### workshpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collate_batch(batch):\n",
    "#     # batch cointains a list of tuples of structure (sequence, target)\n",
    "#     data = [torch.from_numpy(item[0]) for item in batch]\n",
    "#     # print(len(data))\n",
    "#     data = pack_sequence(data, enforce_sorted=False)\n",
    "#     # print(len(data))\n",
    "#     targets = np.array([item[1] for item in batch])\n",
    "#     return data.to(device), torch.tensor(targets).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0161c84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "for features,targets in test_loader:\n",
    "    print(len(features))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8853f6",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd5841",
   "metadata": {},
   "source": [
    "[ref1](https://stackoverflow.com/questions/44643137/how-do-you-use-pytorch-packedsequence-in-code)\n",
    "[ref2](https://www.crosstab.io/articles/time-series-pytorch-lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8794a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: clean up code, understand it better\n",
    "# can add normalizatoin, dropouts, regularization\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "class RegressionLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM model to find the charge of three particles\n",
    "    \"\"\"\n",
    "    def __init__(self, inp_size=2, hidden_size=110, n_layers=1, batch_size=8):\n",
    "        super(RegressionLSTM, self).__init__()\n",
    "        \n",
    "        self.inp_size = inp_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size = self.inp_size,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.n_layers,\n",
    "            batch_first = True\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_size, out_features=3)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.n_layers, self.batch_size ,self.hidden_size).requires_grad_()\n",
    "        c0 = torch.zeros(self.n_layers, self.batch_size, self.hidden_size).requires_grad_()\n",
    "        \n",
    "        _,(hn,_) = self.rnn(x,(h0,c0))\n",
    "        output = self.linear(hn[0])\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bd2d70",
   "metadata": {},
   "source": [
    "### rough work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d62b5aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0185,  0.0870,  0.0483],\n",
      "        [-0.0731,  0.0732,  0.0449],\n",
      "        [-0.0878,  0.0741,  0.0564]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.9951, -0.4482, -0.2730],\n",
      "        [-0.9845, -0.1668, -0.3479],\n",
      "        [-0.0918, -0.3541, -0.6817]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "num_layers = 1\n",
    "hidden_size = 110\n",
    "input_size = 2\n",
    "batch_size = 3\n",
    "rnn = nn.LSTM(input_size =2, hidden_size = 110, num_layers = 1, batch_first = True)\n",
    "# lSTM output is (batch_size,seq_len, num_directions * hidden_size)\n",
    "lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "linear = nn.Linear(in_features= hidden_size, out_features=3)\n",
    "\n",
    "for batch, target in train_loader:\n",
    "    \n",
    "    # seq_len, batch_size\n",
    "    h0 = torch.zeros(num_layers, batch_size ,hidden_size).requires_grad_()\n",
    "    c0 = torch.zeros(num_layers, batch_size, hidden_size).requires_grad_()\n",
    "    # hidden = (h0,c0)\n",
    "    # out,_ = rnn(batch,h0)\n",
    "    o, (h0, c0) = lstm(batch,(h0,c0))\n",
    "    out = linear(h0[0])#.flatten()\n",
    "    print(out)\n",
    "    print(target)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5192ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "# https://stackoverflow.com/questions/44643137/how-do-you-use-pytorch-packedsequence-in-code\n",
    "\n",
    "\n",
    "# data = [torch.tensor([1]),\n",
    "#         torch.tensor([2, 3, 4, 5]), \n",
    "#         torch.tensor([6, 7]),\n",
    "#         torch.tensor([8, 9, 10])]\n",
    "\n",
    "data = [torch.tensor(data).float() for data in simulation_train[:2]]\n",
    "lengths = [d.size(0) for d in data]\n",
    "\n",
    "padded_data = pad_sequence(data, batch_first=True, padding_value=0) \n",
    "padded_data.required_grad = True\n",
    "# embedding = nn.Embedding(20, 4, padding_idx=0)\n",
    "# embeded_data = embedding(padded_data)\n",
    "\n",
    "packed_data = pack_padded_sequence(padded_data, lengths, batch_first=True, enforce_sorted=False)\n",
    "lstm = nn.LSTM(input_size=2, hidden_size=3, batch_first=True)\n",
    "o, (h, c) = lstm(packed_data)\n",
    "\n",
    "# (h, c) is the needed final hidden and cell state, with index already restored correctly by LSTM.\n",
    "# but o is a PackedSequence object, to restore to the original index:\n",
    "\n",
    "unpacked_o, unpacked_lengths = pad_packed_sequence(o, batch_first=True)\n",
    "# now unpacked_o, (h, c) is just like the normal output you expected from a lstm layer.\n",
    "\n",
    "print(unpacked_o, unpacked_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e443b7f",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54d99d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainng and validation for every epoch\n",
    "\n",
    "def train(model, train_loader, val_loader, num_epochs, loss_fn, save_name):\n",
    "    \n",
    "    best_val_loss = float(\"Inf\") \n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        for X, y in tqdm(train_loader):\n",
    "            output = model(X)\n",
    "            loss = loss_fn(output, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss/ len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "\n",
    "        val_running_loss = 0.0\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for X,y in val_loader:\n",
    "                output = model(X)\n",
    "                loss = loss_fn(output, y)\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_running_loss/ len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print('Epoch [{}/{}], train_loss: {:.4f}, val_loss: {:.4f}'\n",
    "                .format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                save_checkpoint(save_name, model, optimizer, best_val_loss)\n",
    "    \n",
    "    print('Finished Training!!')\n",
    "    return train_losses, val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5a5b0aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:20<00:00,  4.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], train_loss: 0.0035, val_loss: 0.0349\n",
      "Model saved to ==> test_run1.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:21<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], train_loss: 0.0034, val_loss: 0.0339\n",
      "Model saved to ==> test_run1.pt\n",
      "Finished Training!!\n"
     ]
    }
   ],
   "source": [
    "#todo\n",
    "from tqdm import tqdm \n",
    "\n",
    "lr = 1e-5\n",
    "hidden_units = 16\n",
    "\n",
    "model = RegressionLSTM(batch_size=batch_len)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "num_epochs = 2\n",
    "\n",
    "save_path = 'test_run1.pt'\n",
    "train_losses, val_losses = train(model, train_loader, val_loader, \n",
    "                                num_epochs, loss_fn, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "080c7a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting training vs validation loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label=\"Validation Loss\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1.0), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7f947d",
   "metadata": {},
   "source": [
    "### workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58348edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:20<00:00,  4.98it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "lr = 1e-5\n",
    "hidden_units = 16\n",
    "\n",
    "model = RegressionLSTM(batch_size=batch_len)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "total_loss = 0\n",
    "# num_batches = \n",
    "model.train()\n",
    "\n",
    "for X,y in tqdm(train_loader):\n",
    "    output = model(X)\n",
    "    loss = loss_fn(output,y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for X,y in val_loader:\n",
    "        output = model(X)\n",
    "        loss = loss_fn(output, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "176b3ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_running_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for X,y in val_loader:\n",
    "        output = model(X)\n",
    "        loss = loss_fn(output, y)\n",
    "    val_running_loss += loss\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da139d5b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebed03ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo : evaluate the model performance on the test set\n",
    "# check the training example it performs the worst on \n",
    "# try to obtain possible reasons for such performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af7ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a3422e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a59808b",
   "metadata": {},
   "source": [
    "# Task 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64a855d",
   "metadata": {},
   "source": [
    "## Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b935865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec19a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f189d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "867aabb3",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36fe2739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b1ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf2800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "826fae3f",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db3fce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ddb47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee069fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c87278a2",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cbb6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6f4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c10d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "adc65bd17b90bc81ceb5a25ba99c9506844573e4b95946b15baa885a4f73e2ea"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
