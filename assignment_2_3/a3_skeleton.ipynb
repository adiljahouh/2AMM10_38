{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "963690b2",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_2_3/a3_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8459f1",
   "metadata": {},
   "source": [
    "# Group Number:\n",
    "\n",
    "# Student 1: Adil \n",
    "\n",
    "# Student 2: Anvitha\n",
    "\n",
    "# Student 3: Srinidhi Ilango"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde28458",
   "metadata": {},
   "source": [
    "# Downloading Data and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0580a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce00edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zip(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    zipf = ZipFile(io.BytesIO(response.content))\n",
    "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
    "\n",
    "def load_pickle(zipfile, fn):\n",
    "    return pickle.load(io.BytesIO(zipfile[fn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb77a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/cwqGaS22KXgnXtg/download')\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "simulation_{train, valid, test} is stored as a list of simulations. \n",
    "Each simulation is a numpy array of size (t, 2): For t timesteps an x and y coordinate of our particle.\n",
    "\"\"\"\n",
    "simulation_train = load_pickle(data, 'data/train/simulation.pickle')  # 3.1 + 3.2\n",
    "simulation_valid = load_pickle(data, 'data/valid/simulation.pickle')  # 3.1 + 3.2\n",
    "simulation_test = load_pickle(data, 'data/test/simulation.pickle')  # 3.1 + 3.2\n",
    "\n",
    "\"\"\"\n",
    "charges_{train, valid, test} is stored as a list of simulation-charges. \n",
    "These charges are stored as numpy arrays of size (3,): One value for each charge.\n",
    "\"\"\"\n",
    "charges_train = load_pickle(data, 'data/train/charges.pickle')  # 3.1\n",
    "charges_valid = load_pickle(data, 'data/valid/charges.pickle')  # 3.1\n",
    "charges_test = load_pickle(data, 'data/test/charges.pickle')  # 3.1\n",
    "\n",
    "\"\"\"\n",
    "simulation_continued_{train, valid, test} is stored as a list of simulations. \n",
    "Each simulation is a numpy array of size (t, 2): For t timesteps an x and y coordinate of our particle.\n",
    "\"\"\"\n",
    "simulation_continued_train = load_pickle(data, 'data/train/simulation_continued.pickle')  # 3.2\n",
    "simulation_continued_valid = load_pickle(data, 'data/valid/simulation_continued.pickle')  # 3.2\n",
    "simulation_continued_test = load_pickle(data, 'data/test/simulation_continued.pickle')  # 3.2\n",
    "\n",
    "\"\"\"\n",
    "Note that the indices are shared throughout the different lists, e.g., for the 4th training simulation:\n",
    "simulation_train[3] contains its initial simulation\n",
    "charges_train[3] contains the charges associated with the simulation\n",
    "simulation_continued_train[3] contains the continuation of the simulation \n",
    "                --> simulation_continued_train[3][0] is the state after simulation_train[3][-1]\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a3438a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of no. datapoints:\n",
      "\n",
      "Task 3.1:\n",
      "800 train, 100 validation, 100 test simulations\n",
      "800 train, 100 validation, 100 test charge pairs\n",
      "\n",
      "Task 3.2:\n",
      "Since len(simulation_continued_train) < len(simulation_train), we can only use a subset of initial simulations\n",
      "We cut simulation_train down to the first 150 samples in simulation_train_task32\n",
      "150 train, 100 validation, 100 test simulations\n",
      "150 train, 100 validation, 100 test continuations\n",
      "\n",
      "For task 3.1, use:\n",
      "simulation_train + charges_train\n",
      "simulation_valid + charges_valid\n",
      "simulation_test + charges_test\n",
      "\n",
      "For task 3.2, use:\n",
      "simulation_train_task32 + simulation_continued_train\n",
      "simulation_valid + simulation_continued_valid\n",
      "simulation_test + simulation_continued_test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Overview of no. datapoints:\\n')\n",
    "\n",
    "print('Task 3.1:')\n",
    "print(f'{len(simulation_train)} train, {len(simulation_valid)} validation, {len(simulation_test)} test simulations')\n",
    "print(f'{len(charges_train)} train, {len(charges_valid)} validation, {len(charges_test)} test charge pairs')\n",
    "print()\n",
    "\n",
    "print('Task 3.2:')\n",
    "print('Since len(simulation_continued_train) < len(simulation_train), we can only use a subset of initial simulations')\n",
    "print('We cut simulation_train down to the first 150 samples in simulation_train_task32')\n",
    "simulation_train_task32 = simulation_train[:150]\n",
    "print(f'{len(simulation_train_task32)} train, {len(simulation_valid)} validation, {len(simulation_test)} test simulations')\n",
    "print(f'{len(simulation_continued_train)} train, {len(simulation_continued_valid)} validation, {len(simulation_continued_test)} test continuations')\n",
    "\n",
    "print(f\"\"\"\n",
    "For task 3.1, use:\n",
    "{chr(10).join([\"simulation_{} + charges_{}\".format(t, t) for t in [\"train\", \"valid\", \"test\"]])}\n",
    "\n",
    "For task 3.2, use:\n",
    "{chr(10).join([\"simulation_{} + simulation_continued_{}\".format(*((t[0], t[1]) if isinstance(t, tuple) else (t, t))) for t in [(\"train_task32\", \"train\"), \"valid\", \"test\"]])}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cfafdb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print some shapes:\n",
      "\n",
      "simulation_train[0].shape: (103, 2) -> (t, 2), (x, y) at every t)\n",
      "charges_train[0].shape: (3,) -> charges for the simulation\n",
      "simulation_continued_train[0].shape: (54, 2) -> (t, 2), (x, y) at every t)\n",
      "----\n",
      "\n",
      "simulation_train[1].shape: (97, 2) -> (t, 2), (x, y) at every t)\n",
      "charges_train[1].shape: (3,) -> charges for the simulation\n",
      "simulation_continued_train[1].shape: (45, 2) -> (t, 2), (x, y) at every t)\n",
      "----\n",
      "\n",
      "simulation_train[2].shape: (99, 2) -> (t, 2), (x, y) at every t)\n",
      "charges_train[2].shape: (3,) -> charges for the simulation\n",
      "simulation_continued_train[2].shape: (47, 2) -> (t, 2), (x, y) at every t)\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Print some shapes:\\n')\n",
    "for i in range(3):\n",
    "    print('simulation_train[{}].shape:'.format(i), simulation_train[i].shape, '-> (t, 2), (x, y) at every t)')\n",
    "    print('charges_train[{}].shape:'.format(i), charges_train[i].shape, '-> charges for the simulation')\n",
    "    print('simulation_continued_train[{}].shape:'.format(i), simulation_continued_train[i].shape, '-> (t, 2), (x, y) at every t)')\n",
    "    print('----\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9106543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_example(x, x_gt=None, x_pred=None, fn=None):\n",
    "    charge_locations = np.array([[-1.53846154, -1.53846154],\n",
    "                                 [ 1.53846154, -1.53846154],\n",
    "                                 [ 0.        ,  1.53846154]])  # charge locations are fixed\n",
    "    fig = plt.figure()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-5., 5.])\n",
    "    axes.set_ylim([-5., 5.])\n",
    "    cmap = matplotlib.cm.get_cmap('tab20')\n",
    "    plt.plot(x[:, 0], x[:, 1], color=cmap(0))\n",
    "    plt.plot(x[0, 0], x[0, 1], 'd', color=cmap(1))\n",
    "    fig.set_size_inches(5, 5)\n",
    "    for charge in charge_locations:\n",
    "        plt.plot(charge[0], charge[1], 'd', color='black')\n",
    "    if x_gt is not None:\n",
    "        plt.plot(x_gt[:, 0], x_gt[:, 1], color='red', linewidth=.5)\n",
    "    if x_pred is not None:\n",
    "        plt.plot(x_pred[:, 0], x_pred[:, 1], color='green', linestyle='--')\n",
    "    if fn is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d28681a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charges are [-0.09808531 -0.5563076  -0.58221579]\n"
     ]
    }
   ],
   "source": [
    "test_idx = np.random.randint(150)\n",
    "plot_example(simulation_train[test_idx], simulation_continued_train[test_idx])\n",
    "print(f'Charges are {charges_train[test_idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883762b1",
   "metadata": {},
   "source": [
    "# Task 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1ddabe",
   "metadata": {},
   "source": [
    "## Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fe48be",
   "metadata": {},
   "source": [
    "Here, we deliberated over one of the following two options as the simulations have different lengths:\n",
    "1. zero padding to match the simulation lenghts\n",
    "2. without zero padding, pass one simuation at a time into the network and aggregate the outputs for backprop [ref1](https://discuss.pytorch.org/t/dataloader-for-various-length-of-data/6418/12#:~:text=2%20MONTHS%20LATER-,GalAvineri,-cdjhz), [ref2](https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch)\n",
    "\n",
    "We now try the second option <br>\n",
    "-- the model should be invariant to rotation, not sure about the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd9df856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo \n",
    "#1. can add data normalization later\n",
    "#2: data augmentation - slice through longer time points as the outputs must remain same\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "# from torch.nn.utils.rnn import pack_sequence\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "# def collate_batch(batch):\n",
    "#     # batch cointains a list of tuples of structure (sequence, target)\n",
    "#     data = [torch.from_numpy(item[0]) for item in batch]\n",
    "#     # print(len(data))\n",
    "#     data = pack_sequence(data, enforce_sorted=False)\n",
    "#     # print(len(data))\n",
    "#     targets = np.array([item[1] for item in batch])\n",
    "#     return data.to(device), torch.tensor(targets).to(device)\n",
    "\n",
    "\n",
    "def collate_batch(batch):\n",
    "    '''\n",
    "    Args:\n",
    "        batch: batch sizes list of tuples (features, target)\n",
    "    \n",
    "    Returns:\n",
    "        packed data and corresponding targets\n",
    "    \n",
    "    '''\n",
    "    data = [torch.from_numpy(item[0]).float() for item in batch]\n",
    "    lengths = [d.size(0) for d in data]\n",
    "\n",
    "    padded_data = pad_sequence(data, batch_first=True, padding_value=0)\n",
    "    packed_data = pack_padded_sequence(padded_data, lengths, batch_first=True, enforce_sorted=False)\n",
    "    \n",
    "    targets = np.array([item[1] for item in batch])\n",
    "\n",
    "    return packed_data.to(device), torch.tensor(targets).float().to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ec1e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a DataLoader used \n",
    "train_loader = DataLoader(tuple(zip(simulation_train, charges_train)), batch_size =3, \n",
    "                        collate_fn = collate_batch,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0161c84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "for features,targets in train_loader:\n",
    "    print(len(features))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8853f6",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd5841",
   "metadata": {},
   "source": [
    "[ref1](https://stackoverflow.com/questions/44643137/how-do-you-use-pytorch-packedsequence-in-code)\n",
    "[ref2](https://www.crosstab.io/articles/time-series-pytorch-lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8794a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: clean up code, understand it better\n",
    "from torch import nn\n",
    "\n",
    "class RegressionLSTM(nn.Module):\n",
    "    def __init__(self, inp_size=2, hidden_size=110, n_layers=1, batch_size=3):\n",
    "        # super(RegressionLSTM, self).__init__()\n",
    "        super().__init__()\n",
    "\n",
    "        self.inp_size = inp_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size = self.inp_size,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.n_layers,\n",
    "            batch_first = True\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_size, out_features=3)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.n_layers, self.batch_size ,hidden_size).requires_grad_()\n",
    "        c0 = torch.zeros(self.n_layers, self.batch_size, hidden_size).requires_grad_()\n",
    "        \n",
    "        _,(hn,_) = self.rnn(x,(h0,c0))\n",
    "        output = self.linear(hn[0])\n",
    "\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bd2d70",
   "metadata": {},
   "source": [
    "### rough work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d62b5aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0185,  0.0870,  0.0483],\n",
      "        [-0.0731,  0.0732,  0.0449],\n",
      "        [-0.0878,  0.0741,  0.0564]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.9951, -0.4482, -0.2730],\n",
      "        [-0.9845, -0.1668, -0.3479],\n",
      "        [-0.0918, -0.3541, -0.6817]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "num_layers = 1\n",
    "hidden_size = 110\n",
    "input_size = 2\n",
    "batch_size = 3\n",
    "rnn = nn.LSTM(input_size =2, hidden_size = 110, num_layers = 1, batch_first = True)\n",
    "# lSTM output is (batch_size,seq_len, num_directions * hidden_size)\n",
    "lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "linear = nn.Linear(in_features= hidden_size, out_features=3)\n",
    "\n",
    "for batch, target in train_loader:\n",
    "    \n",
    "    # seq_len, batch_size\n",
    "    h0 = torch.zeros(num_layers, batch_size ,hidden_size).requires_grad_()\n",
    "    c0 = torch.zeros(num_layers, batch_size, hidden_size).requires_grad_()\n",
    "    # hidden = (h0,c0)\n",
    "    # out,_ = rnn(batch,h0)\n",
    "    o, (h0, c0) = lstm(batch,(h0,c0))\n",
    "    out = linear(h0[0])#.flatten()\n",
    "    print(out)\n",
    "    print(target)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5192ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "# https://stackoverflow.com/questions/44643137/how-do-you-use-pytorch-packedsequence-in-code\n",
    "\n",
    "\n",
    "# data = [torch.tensor([1]),\n",
    "#         torch.tensor([2, 3, 4, 5]), \n",
    "#         torch.tensor([6, 7]),\n",
    "#         torch.tensor([8, 9, 10])]\n",
    "\n",
    "data = [torch.tensor(data).float() for data in simulation_train[:2]]\n",
    "lengths = [d.size(0) for d in data]\n",
    "\n",
    "padded_data = pad_sequence(data, batch_first=True, padding_value=0) \n",
    "padded_data.required_grad = True\n",
    "# embedding = nn.Embedding(20, 4, padding_idx=0)\n",
    "# embeded_data = embedding(padded_data)\n",
    "\n",
    "packed_data = pack_padded_sequence(padded_data, lengths, batch_first=True, enforce_sorted=False)\n",
    "lstm = nn.LSTM(input_size=2, hidden_size=3, batch_first=True)\n",
    "o, (h, c) = lstm(packed_data)\n",
    "\n",
    "# (h, c) is the needed final hidden and cell state, with index already restored correctly by LSTM.\n",
    "# but o is a PackedSequence object, to restore to the original index:\n",
    "\n",
    "unpacked_o, unpacked_lengths = pad_packed_sequence(o, batch_first=True)\n",
    "# now unpacked_o, (h, c) is just like the normal output you expected from a lstm layer.\n",
    "\n",
    "print(unpacked_o, unpacked_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e443b7f",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a5b0aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo\n",
    "lr = 1e-5\n",
    "hidden_units = 16\n",
    "\n",
    "model = RegressionLSTM()\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58348edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267/267 [00:18<00:00, 14.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "total_loss = 0\n",
    "# num_batches = \n",
    "model.train()\n",
    "\n",
    "for X,y in tqdm(train_loader):\n",
    "    output = model(X)\n",
    "    loss = loss_fn(output,y)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "\n",
    "# avg_loss = total_loss/num_batched\n",
    "\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "176b3ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3542313864280222"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da139d5b",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebed03ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af7ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a3422e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a59808b",
   "metadata": {},
   "source": [
    "# Task 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64a855d",
   "metadata": {},
   "source": [
    "## Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b935865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec19a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f189d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "867aabb3",
   "metadata": {},
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36fe2739",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b1ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf2800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "826fae3f",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db3fce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ddb47d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee069fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c87278a2",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cbb6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6f4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c10d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "adc65bd17b90bc81ceb5a25ba99c9506844573e4b95946b15baa885a4f73e2ea"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
