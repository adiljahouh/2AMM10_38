{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730fd591",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_4/assignment_4_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f8d18",
   "metadata": {},
   "source": [
    "# Group Number:\n",
    "\n",
    "# Student 1:\n",
    "\n",
    "# Student 2:\n",
    "\n",
    "# Student 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "# other imports go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and inspect data\n",
    "data_location = 'https://surfdrive.surf.nl/files/index.php/s/K3ArFDQJb5USQ6K/download'\n",
    "data_request = requests.get(data_location)\n",
    "full_data = pickle.loads(data_request.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['unlabeled_data', 'labeled_data', 'representative_set_1', 'representative_set_2'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for data augmentation pipeline \n",
    "labeled_data_full = full_data['labeled_data']\n",
    "train_data = labeled_data_full['data']\n",
    "train_labels = labeled_data_full['labels']\n",
    "unlabeled_data = full_data['unlabeled_data']\n",
    "train_data.shape\n",
    "full_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "from torch.nn.functional import normalize\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels = None):\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        if labels is not None:\n",
    "            self.labels = torch.FloatTensor(labels)\n",
    "        else:\n",
    "            self.labels = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index] #\n",
    "        if self.labels is not None:\n",
    "            y = self.labels[index]  # .view(1,2,5)\n",
    "        else:\n",
    "            y = np.array([])\n",
    "\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 5])\n"
     ]
    }
   ],
   "source": [
    "train_dataset=MyDataset(train_data, train_labels) # Normalization not the same for\n",
    "# val_dataset = MyDataset(velocities_valid, positions_valid, charges_valid, time_id = 1, norm = True, transform=None) \n",
    "# test_dataset = MyDataset(velocities_test, positions_test, charges_test, time_id = 1, norm = True, transform=None) \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128)\n",
    "for x, y in train_loader:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training VAE...\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([80, 1, 32, 32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[128, 1024]' is invalid for input of size 81920",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-0a93cee80adc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[128, 1024]' is invalid for input of size 81920"
     ]
    }
   ],
   "source": [
    "# code for model definitions goes here\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "latent_dim = 5\n",
    "x_dim = 32*32\n",
    "hidden_dim = 500\n",
    "\n",
    "lr = 1e-3\n",
    "epochs = 1\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc_input = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc_hidden = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_sigma = nn.Linear (hidden_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = torch.relu(self.fc_input(x))\n",
    "        h = torch.relu(self.fc_hidden(h))\n",
    "        mu = self.fc_mu(h)\n",
    "        log_sigma = self.fc_sigma(h)\n",
    "        z = self.reparameterization(mu, log_sigma)\n",
    "\n",
    "        return z, mu, log_sigma\n",
    "    \n",
    "    def reparameterization(self, mu, log_sigma):\n",
    "        sigma = torch.exp(log_sigma)\n",
    "        epsilon = torch.randn_like(sigma)\n",
    "        z = mu + sigma * epsilon\n",
    "        \n",
    "        return z\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc_hidden1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc_hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_output = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = torch.relu(self.fc_hidden1(x))\n",
    "        h = torch.relu(self.fc_hidden2(h))\n",
    "        x_reconstr = torch.sigmoid(self.fc_output(h))\n",
    "        return x_reconstr\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "                \n",
    "    def forward(self, x):\n",
    "        z, mu, log_sigma = self.encoder(x)\n",
    "        x_reconstr = self.decoder(z)\n",
    "        \n",
    "        return x_reconstr, mu, log_sigma\n",
    "\n",
    "\n",
    "cuda = True  # NOTE: if running in Google Colab, make sure to go to \"Edit > Notebook settings\" and set \"Hardware accelerator\" to \"GPU\"\n",
    "DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "encoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "decoder = Decoder(latent_dim=latent_dim, hidden_dim=hidden_dim, output_dim=x_dim)\n",
    "\n",
    "vae = VAE(encoder=encoder, decoder=decoder).to(DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "def loss_function(x, x_reconstr, mu, log_sigma):\n",
    "    reconstr_loss = nn.functional.mse_loss(x_reconstr, x, reduction='sum')\n",
    "    kl_loss = 0.5 * torch.sum(mu.pow(2) + (2*log_sigma).exp() - 2*log_sigma - 1)\n",
    "    total_loss = reconstr_loss + kl_loss\n",
    "    return total_loss, reconstr_loss, kl_loss\n",
    "\n",
    "optimizer = optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "print(\"Start training VAE...\")\n",
    "vae.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    overall_loss = 0\n",
    "    overall_reconstr_loss = 0\n",
    "    overall_kl_loss = 0\n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        print(x.shape)\n",
    "        x = x.view(128, x_dim)\n",
    "        x = x.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_reconstr, mu, log_sigma = vae(x)\n",
    "        loss, reconstr_loss, kl_loss = loss_function(x, x_reconstr, mu, log_sigma)\n",
    "        \n",
    "        overall_loss += loss.item()\n",
    "        overall_reconstr_loss += reconstr_loss.item()\n",
    "        overall_kl_loss += kl_loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    n_datapoints = batch_idx * 128\n",
    "    print(\"\\tEpoch\", epoch + 1, \"\\tAverage Loss: \", overall_loss / n_datapoints, \"\\tReconstruction Loss:\", overall_reconstr_loss / n_datapoints, \"\\tKL Loss:\", overall_kl_loss / n_datapoints)\n",
    "    \n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your training and validation loop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection, Validation, and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect, validate, and analyse your trained model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4158c455f6fbd238463d225e32374cd628fb465de0e99af1b601eff60f49c402"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
