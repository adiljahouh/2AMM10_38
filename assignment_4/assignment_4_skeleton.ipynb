{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730fd591",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_4/assignment_4_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f8d18",
   "metadata": {},
   "source": [
    "# Group Number:\n",
    "\n",
    "# Student 1:\n",
    "\n",
    "# Student 2:\n",
    "\n",
    "# Student 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "# other imports go here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and inspect data\n",
    "data_location = 'https://surfdrive.surf.nl/files/index.php/s/K3ArFDQJb5USQ6K/download'\n",
    "data_request = requests.get(data_location)\n",
    "full_data = pickle.loads(data_request.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation and pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['unlabeled_data', 'labeled_data', 'representative_set_1', 'representative_set_2'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code for data augmentation pipeline \n",
    "labeled_data_full = full_data['labeled_data']\n",
    "train_data = labeled_data_full['data']\n",
    "train_labels = labeled_data_full['labels']\n",
    "unlabeled_data = full_data['unlabeled_data']\n",
    "train_data.shape\n",
    "full_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "from torch.nn.functional import normalize\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels = None):\n",
    "        self.data = torch.FloatTensor(data)\n",
    "        if labels is not None:\n",
    "            self.labels = torch.FloatTensor(labels)\n",
    "        else:\n",
    "            self.labels = None\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]  \n",
    "        x = x / 255 # normalize\n",
    "        if self.labels is not None:\n",
    "            y = self.labels[index] # .view(1,2,5)\n",
    "        else:\n",
    "            y = np.array([])\n",
    "\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
      "torch.Size([100, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "train_dataset=MyDataset(unlabeled_data)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100)\n",
    "for x, y in train_loader:\n",
    "    print(x)\n",
    "    print(x.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training VAE...\n",
      "\tEpoch 1 \tAverage Loss:  45.37398701435811 \tReconstruction Loss: 41.462913615694376 \tKL Loss: 3.9110733421796997\n",
      "\tEpoch 2 \tAverage Loss:  28.301915155948357 \tReconstruction Loss: 23.17098951420729 \tKL Loss: 5.130925645275926\n",
      "\tEpoch 3 \tAverage Loss:  26.68729455425012 \tReconstruction Loss: 21.33390914858078 \tKL Loss: 5.353385449265882\n",
      "\tEpoch 4 \tAverage Loss:  25.8711979009562 \tReconstruction Loss: 20.316018910058215 \tKL Loss: 5.555178967332288\n",
      "\tEpoch 5 \tAverage Loss:  25.354715298096647 \tReconstruction Loss: 19.66483805181437 \tKL Loss: 5.689877267491403\n",
      "\tEpoch 6 \tAverage Loss:  24.97050038459218 \tReconstruction Loss: 19.132133463855876 \tKL Loss: 5.83836688067462\n",
      "\tEpoch 7 \tAverage Loss:  24.647955223289696 \tReconstruction Loss: 18.720558252518703 \tKL Loss: 5.927396947205297\n",
      "\tEpoch 8 \tAverage Loss:  24.430987808050798 \tReconstruction Loss: 18.415758061353763 \tKL Loss: 6.015229718418195\n",
      "\tEpoch 9 \tAverage Loss:  24.234366101592663 \tReconstruction Loss: 18.112464330960425 \tKL Loss: 6.121901843685901\n",
      "\tEpoch 10 \tAverage Loss:  24.12555220084761 \tReconstruction Loss: 17.921149416890383 \tKL Loss: 6.204402812236064\n",
      "\tEpoch 11 \tAverage Loss:  23.951845382631515 \tReconstruction Loss: 17.69795788150036 \tKL Loss: 6.253887451643189\n",
      "\tEpoch 12 \tAverage Loss:  23.894486880504946 \tReconstruction Loss: 17.61469797730906 \tKL Loss: 6.279788898482746\n",
      "\tEpoch 13 \tAverage Loss:  23.716271378800677 \tReconstruction Loss: 17.417309706993546 \tKL Loss: 6.298961624675736\n",
      "\tEpoch 14 \tAverage Loss:  23.660286247813104 \tReconstruction Loss: 17.320328746191784 \tKL Loss: 6.3399574969081804\n",
      "\tEpoch 15 \tAverage Loss:  23.606493433654077 \tReconstruction Loss: 17.24854863111577 \tKL Loss: 6.357944868522261\n",
      "\tEpoch 16 \tAverage Loss:  23.570162273392253 \tReconstruction Loss: 17.202216052198963 \tKL Loss: 6.367946263611547\n",
      "\tEpoch 17 \tAverage Loss:  23.48298285171332 \tReconstruction Loss: 17.091524111478947 \tKL Loss: 6.391458780296061\n",
      "\tEpoch 18 \tAverage Loss:  23.404478024515868 \tReconstruction Loss: 17.01699245614895 \tKL Loss: 6.387485641420578\n",
      "\tEpoch 19 \tAverage Loss:  23.36925862315999 \tReconstruction Loss: 16.9572672604594 \tKL Loss: 6.411991360344022\n",
      "\tEpoch 20 \tAverage Loss:  23.352615141997465 \tReconstruction Loss: 16.92454862734526 \tKL Loss: 6.428066481660232\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# code for model definitions goes here\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "latent_dim = 5\n",
    "x_dim = 32*32 # should be 32 32 but testing it on 28 28 atm\n",
    "hidden_dim = 500\n",
    "\n",
    "lr = 1e-3\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc_input = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc_hidden = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_sigma = nn.Linear (hidden_dim, latent_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = torch.relu(self.fc_input(x))\n",
    "        h = torch.relu(self.fc_hidden(h))\n",
    "        mu = self.fc_mu(h)\n",
    "        log_sigma = self.fc_sigma(h)\n",
    "        z = self.reparameterization(mu, log_sigma)\n",
    "\n",
    "        return z, mu, log_sigma\n",
    "    \n",
    "    def reparameterization(self, mu, log_sigma):\n",
    "        sigma = torch.exp(log_sigma)\n",
    "        epsilon = torch.randn_like(sigma)\n",
    "        z = mu + sigma * epsilon\n",
    "        \n",
    "        return z\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc_hidden1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc_hidden2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_output = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = torch.relu(self.fc_hidden1(x))\n",
    "        h = torch.relu(self.fc_hidden2(h))\n",
    "        x_reconstr = torch.sigmoid(self.fc_output(h))\n",
    "        return x_reconstr\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "                \n",
    "    def forward(self, x):\n",
    "        z, mu, log_sigma = self.encoder(x)\n",
    "        x_reconstr = self.decoder(z)\n",
    "        \n",
    "        return x_reconstr, mu, log_sigma\n",
    "\n",
    "\n",
    "# cuda = True  # NOTE: if running in Google Colab, make sure to go to \"Edit > Notebook settings\" and set \"Hardware accelerator\" to \"GPU\"\n",
    "# DEVICE = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "\n",
    "encoder = Encoder(input_dim=x_dim, hidden_dim=hidden_dim, latent_dim=latent_dim)\n",
    "decoder = Decoder(latent_dim=latent_dim, hidden_dim=hidden_dim, output_dim=x_dim)\n",
    "\n",
    "vae = VAE(encoder=encoder, decoder=decoder) #.to(DEVICE)\n",
    "\n",
    "\n",
    "\n",
    "def loss_function(x, x_reconstr, mu, log_sigma):\n",
    "    reconstr_loss = nn.functional.mse_loss(x_reconstr, x, reduction='sum')\n",
    "    kl_loss = 0.5 * torch.sum(mu.pow(2) + (2*log_sigma).exp() - 2*log_sigma - 1)\n",
    "    total_loss = reconstr_loss + kl_loss\n",
    "    return total_loss, reconstr_loss, kl_loss\n",
    "\n",
    "optimizer = optim.Adam(vae.parameters(), lr=lr)\n",
    "\n",
    "print(\"Start training VAE...\")\n",
    "vae.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    overall_loss = 0\n",
    "    overall_reconstr_loss = 0\n",
    "    overall_kl_loss = 0\n",
    "    for batch_idx, (x, _) in enumerate(train_loader):\n",
    "        x = x.view(x.shape[0], x_dim)\n",
    "        x = x #.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_reconstr, mu, log_sigma = vae(x)\n",
    "        loss, reconstr_loss, kl_loss = loss_function(x, x_reconstr, mu, log_sigma)\n",
    "        \n",
    "        overall_loss += loss.item()\n",
    "        overall_reconstr_loss += reconstr_loss.item()\n",
    "        overall_kl_loss += kl_loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    n_datapoints = batch_idx * 100\n",
    "    print(\"\\tEpoch\", epoch + 1, \"\\tAverage Loss: \", overall_loss / n_datapoints, \"\\tReconstruction Loss:\", overall_reconstr_loss / n_datapoints, \"\\tKL Loss:\", overall_kl_loss / n_datapoints)\n",
    "    \n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-9.8135e+00, -7.8513e-02,  8.1249e+00,  2.6417e+01, -7.2266e+03],\n",
       "        [-1.0521e+01, -7.2719e+00,  1.2743e+01,  1.2470e+00,  1.6353e+05],\n",
       "        [-1.2339e+01,  1.2947e+05,  1.8986e+01, -7.0713e+00, -6.7309e-01],\n",
       "        [-2.0914e+01, -1.9231e+00,  1.8045e+01,  4.1455e+00, -2.0132e+00],\n",
       "        [-1.0656e+01,  5.5100e+00,  1.0418e+01, -1.4071e+00, -3.7740e+04],\n",
       "        [-9.1636e+00, -5.4948e+03,  2.6198e+00,  2.0623e+00,  5.2142e+01],\n",
       "        [-1.3785e+01,  2.8850e+00,  8.5814e+00, -1.5732e-01,  2.6206e+01],\n",
       "        [-1.1000e+01, -4.2588e+00,  1.0319e+01,  1.9233e+00,  5.4276e+02],\n",
       "        [-3.0660e+01, -5.6718e+00,  2.7112e+01, -1.7166e+00, -5.1036e+00],\n",
       "        [-5.0666e+00, -1.0215e+01,  5.9489e-01, -3.3136e-01, -1.8082e+02],\n",
       "        [-1.1114e+01, -4.6019e+01,  3.5699e+00, -3.2093e+00, -1.2595e+01],\n",
       "        [-1.0067e+01,  9.4589e+02,  4.2327e+00,  2.5071e+00, -9.3977e+03],\n",
       "        [-4.3183e+00,  9.5311e-01,  5.3914e+00, -4.3793e+00, -2.7470e+00],\n",
       "        [-1.9431e+01,  6.2778e-01,  7.8441e+00, -8.2541e+00,  8.4569e+05],\n",
       "        [-1.2281e+01,  4.3485e+00,  1.0771e+01,  1.6542e+01, -1.7562e+04],\n",
       "        [-1.5977e+01, -1.1672e+01,  1.1344e+01, -1.9058e+00,  4.1141e+00],\n",
       "        [-1.1952e+01,  1.3704e+01,  9.7862e+00,  1.5575e+00,  1.7057e+04],\n",
       "        [-1.5367e+01, -1.2618e+04,  5.2131e+00,  7.2519e+00, -5.9074e+03],\n",
       "        [-9.5504e+00,  1.6547e+04,  2.8568e+00, -5.1573e+00,  2.6965e+03],\n",
       "        [-1.3022e+01,  6.9455e-01,  9.4105e+00,  1.6522e+00,  2.7855e+05],\n",
       "        [-1.5107e+00, -4.1104e+01,  3.2644e+00,  3.5082e+00, -5.5822e+02],\n",
       "        [-8.3567e+00, -4.8331e+01,  1.0056e+01, -1.7452e+00,  1.3903e+02],\n",
       "        [-5.8623e+00, -1.2219e+01,  8.7003e+00, -5.8508e+00,  5.9207e+00],\n",
       "        [-2.0879e+01,  1.4899e+03,  1.6739e+01, -2.9109e+00, -9.8954e+02],\n",
       "        [-1.1226e+01, -7.9264e+00,  6.1918e+00, -1.6052e+00,  2.6119e+02],\n",
       "        [-7.6550e+00, -2.1693e+02,  4.9221e-01,  1.1490e+00,  4.4525e-01],\n",
       "        [-7.8663e+00, -3.2139e+04,  1.0195e+01, -2.8802e-01, -1.2979e+02],\n",
       "        [-2.2591e+01, -5.1209e+01,  7.2327e+00, -3.3622e+00,  1.7804e+02],\n",
       "        [-1.1286e+01, -8.4914e+01,  2.1332e+00,  1.1374e+00,  2.4089e+01],\n",
       "        [-1.3440e+01, -6.6766e-01,  1.5647e+01, -9.5994e-01,  8.6214e+04],\n",
       "        [-1.5960e+01,  7.6460e+01,  1.1803e+01, -4.5360e+00,  9.4671e+00],\n",
       "        [-7.2750e+00, -2.0002e+02, -4.7571e+00,  2.5387e+00,  2.7403e+03],\n",
       "        [-6.9480e+00, -6.0836e+00,  8.1774e+00, -1.8964e+00,  5.1835e+01],\n",
       "        [-8.8234e+00, -8.7086e+00,  9.7513e+00, -1.0734e+01, -3.6881e+03],\n",
       "        [-5.7867e+00, -9.4606e+00,  3.1179e+00, -3.3456e+00,  8.6616e+02],\n",
       "        [-1.1900e+01,  2.8441e+04,  8.4421e+00,  3.0296e+00, -1.2007e+03],\n",
       "        [-1.2478e+01,  7.6604e+01,  1.5063e+01, -9.8107e+00,  6.6877e-01],\n",
       "        [-1.7860e+01,  1.0056e+05,  7.4006e+00,  2.9241e+00, -2.9267e+03],\n",
       "        [-1.1976e+01,  2.1677e+01,  5.2671e+00, -2.5400e+00, -5.6442e+02],\n",
       "        [-1.3663e+01,  5.9488e+01,  1.2034e+01, -3.6368e+00, -5.2577e+00],\n",
       "        [-9.7090e+00, -2.0795e+01,  4.2987e+00, -5.3481e+00,  1.4660e+01],\n",
       "        [-5.5613e+00,  2.6476e+00,  2.1608e+00,  9.1879e-01, -5.9125e+00],\n",
       "        [-1.4188e+01,  2.2543e+03,  1.1659e+01,  4.4313e-01, -2.2492e+03],\n",
       "        [-1.1224e+01, -2.6322e-01,  9.5430e+00,  1.6715e+00, -2.3233e+05],\n",
       "        [-1.1600e+01, -7.9028e+00,  1.2084e+01,  1.8437e+00,  4.2740e+01],\n",
       "        [-6.1028e+00, -6.3800e+02,  6.3010e+00,  1.5485e+00,  3.7198e+02],\n",
       "        [-1.2088e+01, -7.1708e+03,  9.2112e+00, -1.7024e+00,  1.2514e+04],\n",
       "        [-2.4831e+01, -1.1157e+00,  1.6958e+01,  3.6713e+00,  1.8845e+00],\n",
       "        [-1.2987e+01,  5.2278e+00,  7.3886e+00, -3.3104e+00,  7.5919e+07],\n",
       "        [-1.7370e+00,  6.8303e+04,  2.8474e+00,  6.1128e-01,  3.0863e+00],\n",
       "        [-5.2176e+00,  5.7876e+01,  4.3369e+00,  1.7452e+00,  3.6575e+00],\n",
       "        [-9.7843e+00, -4.0282e+01,  7.7653e-01, -2.0067e+00, -1.0581e+02],\n",
       "        [-1.0241e+01,  2.2888e+04,  7.4045e+00, -6.2485e+00, -9.7747e+00],\n",
       "        [-1.0923e+01,  2.6343e+03,  3.3858e+00,  2.0527e-01,  1.0084e+05],\n",
       "        [-1.0399e+01, -2.4524e+00,  7.6907e+00, -3.0225e+00,  5.7171e+05],\n",
       "        [-1.5470e+01,  1.9594e+00,  1.1787e+01,  2.9435e-01,  1.8049e+03],\n",
       "        [-3.8004e+00,  9.1150e+00, -6.1497e+00,  2.6718e+00, -5.0240e+00],\n",
       "        [-1.4305e+01, -3.7324e+01,  8.5771e+00,  1.1222e+00,  1.9477e+04],\n",
       "        [-1.0936e+01,  8.1975e+04,  8.5556e+00,  1.0224e-01,  1.1771e+02],\n",
       "        [-1.3101e+01,  1.2096e+03,  3.5369e+00,  1.2913e+00,  1.0251e+03],\n",
       "        [-1.2741e+01, -2.8611e+05,  1.0917e+01,  2.1143e+00,  2.6064e+04],\n",
       "        [-1.1812e+01, -5.8198e+00,  8.8161e+00,  2.8802e+00,  1.1062e+00],\n",
       "        [-1.7186e+01,  5.9931e+00,  2.0167e+01, -1.0114e+01,  2.1637e-01],\n",
       "        [-1.6194e+01, -6.8494e+00,  1.3780e+01, -2.0883e+00,  1.5568e+02],\n",
       "        [-1.3386e+01,  1.8557e+00,  8.0991e+00,  5.4512e-01,  6.9987e+03],\n",
       "        [-1.5512e+01, -8.5844e+04,  1.1707e+01,  2.3256e+00, -9.8096e+04],\n",
       "        [-1.5517e+01,  2.0480e+00,  2.3112e+01,  1.5619e+00, -6.8479e+00],\n",
       "        [-4.2891e+00, -5.0096e+00,  1.9136e+00, -3.9325e+00,  1.9463e+00],\n",
       "        [-1.5368e+01,  1.8897e+02, -2.3307e-01, -2.4376e+00,  2.3014e+05],\n",
       "        [-1.0412e+01, -1.0047e+01,  3.9343e+00, -1.9485e+00, -3.3267e+01],\n",
       "        [-6.2114e+00, -9.9553e+00,  1.2888e+01, -8.2031e+00,  5.0824e+00],\n",
       "        [-7.5257e+00,  2.2832e+04,  6.3052e+00,  6.1202e-01,  3.6400e-01],\n",
       "        [-1.1430e+01,  9.2319e-01,  6.8029e+00,  1.2348e-01, -3.8772e+06],\n",
       "        [-9.1057e+00,  8.6910e+02, -1.7709e-01,  3.8150e-01, -3.8098e+01],\n",
       "        [-1.1154e+01,  3.0688e+04,  1.0970e+01, -3.5548e+00,  3.7587e+05],\n",
       "        [-1.2996e+01, -9.6874e+03,  1.1080e+01, -1.2221e+00,  6.0152e+01],\n",
       "        [-1.4054e+01,  3.4315e+01,  1.0653e+01, -1.0924e+01, -4.1846e+02],\n",
       "        [-1.0046e+01,  9.1015e+01,  8.0711e+00,  2.0361e-01, -2.1804e+03],\n",
       "        [-6.7277e+00,  1.0195e+03,  4.5889e+00, -1.8516e-01,  1.4368e+01],\n",
       "        [-9.0705e+00, -2.2360e+00,  9.3837e+00, -4.5594e+00, -5.0864e+00],\n",
       "        [-6.3993e+00, -4.2823e+00,  5.0460e+00,  7.7264e-01,  1.5803e+01],\n",
       "        [-4.8615e+00,  4.4792e+00,  1.1582e+01, -3.3180e+00, -2.6210e+03],\n",
       "        [-7.2903e+00,  2.5950e+02,  6.1482e+00, -1.4691e+01,  1.5580e+00],\n",
       "        [-9.4778e+00,  2.1851e+05,  2.9367e+00,  3.4606e-02,  1.5396e+03],\n",
       "        [-1.3854e+01, -3.0995e-02,  1.1459e+01,  2.5003e+00, -5.4075e+04],\n",
       "        [-1.2793e+01,  5.5073e-01,  9.6559e+00, -2.0254e+00,  1.6238e+03],\n",
       "        [-1.0473e+01, -6.3168e+00,  1.0694e+01,  1.6001e+00, -7.0048e+02],\n",
       "        [-1.7237e+01,  1.0920e+00,  1.0543e+01,  3.0624e+00,  4.9441e+01],\n",
       "        [-1.2319e+01,  8.4410e+01,  1.2821e+01, -1.0022e+01,  2.4385e+00],\n",
       "        [-1.7917e+01,  8.0347e+01,  2.1436e+01, -1.0447e+01, -1.8276e+00],\n",
       "        [-1.6188e+01,  1.2058e+00,  1.4861e+01,  2.6643e+00, -4.2533e+01],\n",
       "        [-1.2944e+01,  1.0490e+00,  1.0104e+01,  2.6494e+01,  3.9954e+04],\n",
       "        [-8.7089e+00, -4.1174e+00,  1.8753e+01,  1.5085e+01, -1.6787e+01],\n",
       "        [-1.4801e+01, -1.0069e+00,  9.1476e+00, -2.7680e+00, -6.1593e+05],\n",
       "        [-1.0061e+01, -7.8046e+04,  8.0744e+00,  1.2125e+00, -1.8643e+03],\n",
       "        [-8.7396e+00,  2.8893e+01,  2.0089e+00,  1.2322e+00, -1.5412e+02],\n",
       "        [-1.7103e+01,  3.1821e+02,  3.1808e+00, -1.0365e+00,  2.4828e+03],\n",
       "        [-1.1973e+01, -4.6147e-01,  1.0454e+01, -5.4063e-01,  2.9504e+03],\n",
       "        [-9.7290e+00, -7.5134e+00,  1.3667e+01,  4.1580e-02, -3.8384e+04],\n",
       "        [-1.4264e+01, -4.1072e+03,  2.8846e+00,  9.2608e-01,  1.7534e+06]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your training and validation loop here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspection, Validation, and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect, validate, and analyse your trained model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4158c455f6fbd238463d225e32374cd628fb465de0e99af1b601eff60f49c402"
  },
  "kernelspec": {
   "display_name": "Python 3.7.1 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
